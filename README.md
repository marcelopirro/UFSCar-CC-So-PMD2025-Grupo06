# UFSCar-CC-So-PMD2025-Grupo06

**Autores:**
* Marcelo Pirro ‚Äì 800510
* Guilherme Campos Bortoletto ‚Äì 801477

**Projeto:**
**Detec√ß√£o de Fake News com Processamento em Larga Escala Utilizando MongoDB Atlas e Python**

**Ano:** 2025

---

## Resumo

O projeto tem como foco o desenvolvimento de um pipeline completo para a detec√ß√£o autom√°tica de fake news, integrando tecnologias de armazenamento e processamento de dados. Utilizando o **MongoDB Atlas** como banco de dados NoSQL e a biblioteca **Pymongo** em um ambiente **Databricks** para a an√°lise e processamento, o sistema √© capaz de armazenar, transformar e analisar milhares de not√≠cias jornal√≠sticas.

A solu√ß√£o trabalha com um conjunto de dados obtido do Kaggle, contendo aproximadamente 44 mil not√≠cias reais e falsas. Ap√≥s o pr√©-processamento, os registros s√£o inseridos no MongoDB como documentos JSON. A partir da√≠, s√£o realizadas opera√ß√µes de limpeza, tokeniza√ß√£o, vetoriza√ß√£o e transforma√ß√£o com TF-IDF. Com os dados preparados, s√£o treinados modelos de machine learning para classificar os textos como verdadeiros ou falsos.

Al√©m da classifica√ß√£o autom√°tica, o projeto realiza uma an√°lise explorat√≥ria lingu√≠stica, identificando as palavras mais frequentes em conte√∫dos falsos, revelando padr√µes de escrita e vocabul√°rio caracter√≠sticos. O pipeline completo demonstra a viabilidade t√©cnica da integra√ß√£o de um banco de dados NoSQL robusto com bibliotecas de ci√™ncia de dados em Python para tarefas de Processamento de Linguagem Natural (NLP).

## Objetivo

Nosso objetivo √© desenvolver um pipeline completo de detec√ß√£o de not√≠cias falsas (fake news) por meio da an√°lise de padr√µes lingu√≠sticos em textos jornal√≠sticos. Buscamos demonstrar a aplica√ß√£o de tecnologias NoSQL e frameworks de processamento para:

* Armazenar de forma flex√≠vel e escal√°vel um volume significativo de not√≠cias reais e falsas;
* Processar os dados textuais em larga escala utilizando t√©cnicas de NLP (*Natural Language Processing*);
* Treinar e avaliar um modelo de *machine learning* para classificar automaticamente not√≠cias como verdadeiras ou falsas;
* Avaliar a viabilidade da arquitetura proposta no contexto de aplica√ß√µes que demandam robustez e integra√ß√£o direta com bancos de dados;
* Identificar m√©tricas lingu√≠sticas complementares, como as palavras mais frequentes em textos de *fake news*, fornecendo an√°lises explorat√≥rias sobre padr√µes de vocabul√°rio e estilo.

## Tecnologias Escolhidas

### MongoDB Atlas

A escolha de um banco de dados NoSQL como o **MongoDB** √© a mais adequada para este projeto porque lidamos com dados textuais e semi-estruturados (not√≠cias) que variam em formato e conte√∫do. A natureza dos dados tratados ‚Äî not√≠cias jornal√≠sticas ‚Äî envolve estruturas com campos como **t√≠tulo**, **categoria**, **conte√∫do textual** e **data**. O **MongoDB Atlas** resolve esse problema ao utilizar um modelo de documentos **JSON**, que se adapta perfeitamente a esse tipo de dado. Al√©m disso, trata-se de uma solu√ß√£o **gerenciada na nuvem**, com f√°cil escalabilidade horizontal.

Diferente dos bancos relacionais, que exigem esquemas r√≠gidos, o MongoDB oferece uma **estrutura flex√≠vel**, possui **indexa√ß√£o** e **busca textual nativa**, e se integra diretamente com diversas linguagens e frameworks, permitindo o **processamento eficiente** dos dados.

### Mudan√ßa de Estrat√©gia: De PySpark para Pymongo no Databricks

Inicialmente, o projeto previa o uso do **Apache Spark (PySpark)** para o processamento distribu√≠do dos dados. A arquitetura original visava conectar o Spark ao MongoDB Atlas para realizar as transforma√ß√µes em um ambiente de larga escala, aproveitando a capacidade do Spark de distribuir o processamento em clusters.

Contudo, durante o desenvolvimento, enfrentamos uma barreira t√©cnica significativa. A plataforma **Databricks Community Edition**, que era nossa escolha para o processamento distribu√≠do com Spark, **removeu o acesso a clusters computacionais em seu plano livre**. Sem um cluster, a execu√ß√£o do PySpark e do conector `spark-mongodb` tornou-se invi√°vel.

Diante desse obst√°culo, adaptamos a estrat√©gia. **Mantivemos o ambiente Databricks para a execu√ß√£o dos notebooks Python**, mas substitu√≠mos o processamento com PySpark pela biblioteca **Pymongo** para a intera√ß√£o direta com o MongoDB Atlas. Essa abordagem, embora n√£o utilize processamento distribu√≠do, ainda cumpre o requisito de integrar um modelo de dados NoSQL com uma plataforma de processamento de dados, permitindo a execu√ß√£o de todo o pipeline de an√°lise e machine learning.

## Fonte de Dados

* **Dataset**: Fake and Real News Dataset ‚Äì Kaggle
* **Link**: <https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset>
* **Conte√∫do**: Cerca de 44.000 artigos de not√≠cias, divididos nos arquivos `Fake.csv` e `True.csv`.
* **Atributos**: t√≠tulo, conte√∫do, categoria, data de publica√ß√£o.

## Fluxograma do Projeto

1.  **Obten√ß√£o dos Dados** ‚Äì Download dos arquivos CSV do Kaggle.
2.  **Pr√©-processamento Inicial** ‚Äì Limpeza e padroniza√ß√£o em Python.
3.  **Inser√ß√£o no MongoDB Atlas** ‚Äì Cada not√≠cia √© armazenada como um documento JSON em sua respectiva *collection* (`Fake` ou `Real`).
4.  **Leitura com Pymongo no Databricks** ‚Äì Conex√£o com o MongoDB Atlas e leitura dos documentos das *collections*.
5.  **Processamento e An√°lise** ‚Äì Utiliza√ß√£o da biblioteca `scikit-learn` para tokeniza√ß√£o, vetoriza√ß√£o com TF-IDF e prepara√ß√£o dos dados para o modelo.
6.  **Treinamento de Modelos** ‚Äì Aplica√ß√£o de algoritmos de Machine Learning, como Naive Bayes, para classifica√ß√£o.
7.  **An√°lise Textual Explorat√≥ria** ‚Äì Identifica√ß√£o de padr√µes lingu√≠sticos e vocabul√°rio frequente em fake news.
<img width="1920" height="1080" alt="fluxograma" src="https://github.com/user-attachments/assets/6611d4f0-298b-4efc-bca8-a38f65511e47" />

## Desenvolvimento e Implementa√ß√£o

A fase final do projeto concentrou-se na implementa√ß√£o do pipeline de leitura, processamento e classifica√ß√£o usando Python. O c√≥digo foi executado em um **ambiente Databricks**, utilizando a biblioteca `pymongo` para interagir com o MongoDB Atlas.

Abaixo, um resumo das etapas implementadas no script:

#### 1. Conex√£o com o MongoDB Atlas

Primeiro, estabelecemos a conex√£o com o cluster do MongoDB Atlas usando a URI de conex√£o fornecida:

```python
from pymongo import MongoClient

conn_uri = "mongodb+srv://Databricks:1234@pmd2025marcelopirro.nhnozvy.mongodb.net/?retryWrites=true&w=majority"
client = MongoClient(conn_uri)
db = client["Fake_and_Real"]
```

#### 2. Carregamento dos Dados

Os dados, previamente inseridos nas *collections* `Fake` e `Real`, foram carregados em DataFrames do Pandas para facilitar a manipula√ß√£o:

```python
collection_fake = db["Fake"]
fake_data = list(collection_fake.find())
df_fake = pd.DataFrame(fake_data)

collection_real = db["Real"]
real_data = list(collection_real.find())
df_real = pd.DataFrame(real_data)
```

#### 3. Pr√©-processamento e Unifica√ß√£o

Criamos uma coluna `label` para diferenciar as not√≠cias (`0` para falsas, `1` para verdadeiras) e unificamos os dois conjuntos de dados. Em seguida, aplicamos uma fun√ß√£o de limpeza nos textos para remover caracteres especiais, converter para min√∫sculas e retirar *stopwords*:

```python
df_fake["label"] = 0
df_real["label"] = 1
df_total = pd.concat([df_fake, df_real], ignore_index=True)

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    tokens = text.split()
    tokens = [word for word in tokens if word not in stopwords.words('english')]
    return ' '.join(tokens)

df_total["clean_text"] = df_total["text"].apply(preprocess_text)
```

#### 4. Vetoriza√ß√£o e Treinamento do Modelo

Utilizamos a t√©cnica **TF-IDF (Term Frequency-Inverse Document Frequency)** para converter o texto em vetores num√©ricos, limitando o vocabul√°rio √†s 5000 palavras mais relevantes. Por fim, dividimos os dados em conjuntos de treino e teste e treinamos um modelo de classifica√ß√£o **Multinomial Naive Bayes**:

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

vectorizer = TfidfVectorizer(max_features=5000)
X_vect = vectorizer.fit_transform(df_total["clean_text"])
y = df_total["label"]

X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)

model = MultinomialNB()
model.fit(X_train, y_train)
```

#### 5. Avalia√ß√£o dos Resultados

O desempenho do modelo foi avaliado com um relat√≥rio de classifica√ß√£o e uma matriz de confus√£o, que nos permitem medir a acur√°cia, precis√£o e outras m√©tricas importantes para validar a efic√°cia da classifica√ß√£o.

O modelo treinado com **Multinomial Naive Bayes** apresentou um excelente desempenho na tarefa de detec√ß√£o autom√°tica de *fake news*. A avalia√ß√£o do modelo no conjunto de teste resultou em uma **acur√°cia de 94%**, com m√©tricas equilibradas para ambas as classes (not√≠cias falsas e verdadeiras).

Abaixo, destacamos os principais resultados obtidos:

- **Precision** de 94% em ambas as classes, indicando uma baixa taxa de falsos positivos.
- **Recall** de 94% para a classe 0 (fake) e 93% para a classe 1 (real), refletindo uma boa capacidade de identifica√ß√£o dos casos reais.
- **F1-score** de 0.94 e 0.93, demonstrando equil√≠brio entre precis√£o e recall.
- **Matriz de confus√£o** evidencia que a grande maioria das previs√µes foram corretas, com poucos erros relativos.

O pipeline, demonstrou ser eficaz ao integrar **MongoDB Atlas**, **Pymongo**, e **Scikit-learn** em um ambiente **Databricks**, viabilizando um fluxo completo de ingest√£o, processamento e classifica√ß√£o de textos jornal√≠sticos em larga escala.

---

## üìä An√°lise do Relat√≥rio de Classifica√ß√£o

### M√©tricas Principais (Para cada classe):

| **M√©trica**   | **Classe 0 (Fake)** | **Classe 1 (Real)** | **Explica√ß√£o**                                                                 |
|---------------|---------------------|----------------------|----------------------------------------------------------------------------------|
| Precision     | 0.94                | 0.94                 | 94% das previs√µes positivas est√£o corretas (baixa taxa de falsos positivos)      |
| Recall        | 0.94                | 0.93                 | 94% / 93% dos casos reais foram identificados (baixa taxa de falsos negativos)  |
| F1-Score      | 0.94                | 0.93                 | M√©dia harm√¥nica entre Precision e Recall (√≥timo equil√≠brio entre ambos)         |
| Support       | 4733                | 4247                 | N√∫mero de amostras em cada classe no conjunto de teste                          |

### M√©tricas Globais:

| **M√©trica**     | **Valor** | **Explica√ß√£o**                                                                 |
|-----------------|-----------|----------------------------------------------------------------------------------|
| Accuracy        | 0.94      | 94% de acerto geral (excelente para problemas balanceados)                     |
| Macro Avg       | 0.94      | M√©dia simples das m√©tricas (igual peso para ambas as classes)                  |


A matriz de confus√£o abaixo representa o desempenho do modelo na tarefa de classifica√ß√£o de not√≠cias falsas (Fake) e verdadeiras (Real):

```
[[4467  266]
 [ 285 3962]]
```

|                         | **Previsto: Fake (0)** | **Previsto: Real (1)** |
|-------------------------|------------------------|-------------------------|
| **Verdadeiro: Fake (0)**| 4467 ‚úÖ (Verdadeiro Negativo - TN) | 266 ‚ùå (Falso Positivo - FP) |
| **Verdadeiro: Real (1)**| 285 ‚ùå (Falso Negativo - FN)       | 3962 ‚úÖ (Verdadeiro Positivo - TP) |

---

### üß† Interpreta√ß√£o:

- **4467** not√≠cias falsas foram corretamente classificadas como falsas (**Verdadeiros Negativos**).
- **3962** not√≠cias verdadeiras foram corretamente classificadas como verdadeiras (**Verdadeiros Positivos**).
- **266** not√≠cias verdadeiras foram incorretamente classificadas como falsas (**Falsos Positivos**).
- **285** not√≠cias falsas foram incorretamente classificadas como verdadeiras (**Falsos Negativos**).

---

### üìå Conclus√£o:

O modelo errou relativamente pouco em ambos os sentidos:

- Baixo n√∫mero de **falsos positivos** (not√≠cia verdadeira sendo marcada como falsa);
- Baixo n√∫mero de **falsos negativos** (not√≠cia falsa sendo considerada verdadeira).

Esses resultados confirmam que o modelo est√° **bem equilibrado** e apresenta **excelente desempenho**, o que tamb√©m √© refletido nas m√©tricas globais (accuracy, precision, recall, f1-score).

## Resultados Esperados

Ser√° desenvolvido um **pipeline funcional de ponta a ponta** para a detec√ß√£o autom√°tica de *fake news*, abrangendo todas as etapas, desde a ingest√£o dos dados at√© a classifica√ß√£o final dos textos.

O modelo de *machine learning* ser√° avaliado com m√©tricas relevantes, como **acur√°cia**, **precis√£o** e **recall**, proporcionando uma an√°lise quantitativa consistente sobre o desempenho da solu√ß√£o.

Al√©m disso, o projeto visa demonstrar a **viabilidade t√©cnica e pr√°tica** da integra√ß√£o entre **MongoDB Atlas** e **Python (com Pymongo e Scikit-learn)** em um ambiente **Databricks**, utilizando essas tecnologias em um cen√°rio real de **classifica√ß√£o de textos em larga escala**.
