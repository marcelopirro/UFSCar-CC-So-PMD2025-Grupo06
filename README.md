# Projeto de Disciplina ‚Äì **Detec√ß√£o de Fake News com Processamento em Larga Escala Utilizando MongoDB Atlas e Python**


**Universidade Federal de S√£o Carlos**  
**Curso:** Bacharelado em Ci√™ncia da Computa√ß√£o de Sorocaba  
**Disciplina:** Processamento Massivo de Dados  
**Professora:** Profa. Dra. Sahudy Montenegro Gonz√°lez  


**Grupo 06**  

**Integrantes:**
* Marcelo Pirro ‚Äì 800510
* Guilherme Campos Bortoletto ‚Äì 801477

---

## Resumo

O projeto tem como foco o desenvolvimento de um pipeline completo para a detec√ß√£o autom√°tica de fake news, integrando tecnologias de armazenamento e processamento de dados. Utilizando o **MongoDB Atlas** como banco de dados NoSQL e a biblioteca **Pymongo** em um ambiente **Databricks** para a an√°lise e processamento, o sistema √© capaz de armazenar, transformar e analisar milhares de not√≠cias jornal√≠sticas.

A solu√ß√£o trabalha com um conjunto de dados obtido do Kaggle, contendo aproximadamente 44 mil not√≠cias reais e falsas. Ap√≥s o pr√©-processamento, os registros s√£o inseridos no MongoDB como documentos JSON. A partir da√≠, s√£o realizadas opera√ß√µes de limpeza, tokeniza√ß√£o, vetoriza√ß√£o e transforma√ß√£o com TF-IDF. Com os dados preparados, s√£o treinados modelos de machine learning para classificar os textos como verdadeiros ou falsos.

Al√©m da classifica√ß√£o autom√°tica, o projeto realiza uma an√°lise explorat√≥ria lingu√≠stica, identificando as palavras mais frequentes em conte√∫dos falsos, revelando padr√µes de escrita e vocabul√°rio caracter√≠sticos. O pipeline completo demonstra a viabilidade t√©cnica da integra√ß√£o de um banco de dados NoSQL robusto com bibliotecas de ci√™ncia de dados em Python para tarefas de Processamento de Linguagem Natural (NLP).

## Objetivo

Nosso objetivo √© desenvolver um pipeline completo de detec√ß√£o de not√≠cias falsas (fake news) por meio da an√°lise de padr√µes lingu√≠sticos em textos jornal√≠sticos. Buscamos demonstrar a aplica√ß√£o de tecnologias NoSQL e frameworks de processamento para:

* Armazenar de forma flex√≠vel e escal√°vel um volume significativo de not√≠cias reais e falsas;
* Processar os dados textuais em larga escala utilizando t√©cnicas de NLP (*Natural Language Processing*);
* Treinar e avaliar um modelo de *machine learning* para classificar automaticamente not√≠cias como verdadeiras ou falsas;
* Avaliar a viabilidade da arquitetura proposta no contexto de aplica√ß√µes que demandam robustez e integra√ß√£o direta com bancos de dados;
* Identificar m√©tricas lingu√≠sticas complementares, como as palavras mais frequentes em textos de *fake news*, fornecendo an√°lises explorat√≥rias sobre padr√µes de vocabul√°rio e estilo.

## Tecnologias Escolhidas

### MongoDB Atlas

A escolha de um banco de dados NoSQL como o **MongoDB** √© a mais adequada para este projeto porque lidamos com dados textuais e semi-estruturados (not√≠cias) que variam em formato e conte√∫do. A natureza dos dados tratados ‚Äî not√≠cias jornal√≠sticas ‚Äî envolve estruturas com campos como **t√≠tulo**, **categoria**, **conte√∫do textual** e **data**. O **MongoDB Atlas** resolve esse problema ao utilizar um modelo de documentos **JSON**, que se adapta perfeitamente a esse tipo de dado. Al√©m disso, trata-se de uma solu√ß√£o **gerenciada na nuvem**, com f√°cil escalabilidade horizontal.

Diferente dos bancos relacionais, que exigem esquemas r√≠gidos, o MongoDB oferece uma **estrutura flex√≠vel**, possui **indexa√ß√£o** e **busca textual nativa**, e se integra diretamente com diversas linguagens e frameworks, permitindo o **processamento eficiente** dos dados.

### Mudan√ßa de Estrat√©gia: De PySpark para Pymongo no Databricks

Inicialmente, o projeto previa o uso do **Apache Spark (PySpark)** para o processamento distribu√≠do dos dados. A arquitetura original visava conectar o Spark ao MongoDB Atlas para realizar as transforma√ß√µes em um ambiente de larga escala, aproveitando a capacidade do Spark de distribuir o processamento em clusters.

Contudo, durante o desenvolvimento, enfrentamos uma barreira t√©cnica significativa. A plataforma **Databricks Community Edition**, que era nossa escolha para o processamento distribu√≠do com Spark, **removeu o acesso a clusters computacionais em seu plano livre**. Sem um cluster, a execu√ß√£o do PySpark e do conector `spark-mongodb` tornou-se invi√°vel.

Diante desse obst√°culo, adaptamos a estrat√©gia. **Mantivemos o ambiente Databricks para a execu√ß√£o dos notebooks Python**, mas substitu√≠mos o processamento com PySpark pela biblioteca **Pymongo** para a intera√ß√£o direta com o MongoDB Atlas. Essa abordagem, embora n√£o utilize processamento distribu√≠do, ainda cumpre o requisito de integrar um modelo de dados NoSQL com uma plataforma de processamento de dados, permitindo a execu√ß√£o de todo o pipeline de an√°lise e machine learning.

## Fonte de Dados

* **Dataset**: Fake and Real News Dataset ‚Äì Kaggle
* **Link**: <https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset>
* **Conte√∫do**: Cerca de 44.000 artigos de not√≠cias, divididos nos arquivos `Fake.csv` e `True.csv`.
* **Atributos**: t√≠tulo, conte√∫do, categoria, data de publica√ß√£o.

## Fluxograma do Projeto

1.  **Obten√ß√£o dos Dados** ‚Äì Download dos arquivos CSV do Kaggle.
2.  **Pr√©-processamento Inicial** ‚Äì Limpeza e padroniza√ß√£o em Python.
3.  **Inser√ß√£o no MongoDB Atlas** ‚Äì Cada not√≠cia √© armazenada como um documento JSON em sua respectiva *collection* (`Fake` ou `Real`).
4.  **Leitura com Pymongo no Databricks** ‚Äì Conex√£o com o MongoDB Atlas e leitura dos documentos das *collections*.
5.  **Processamento e An√°lise** ‚Äì Utiliza√ß√£o da biblioteca `scikit-learn` para tokeniza√ß√£o, vetoriza√ß√£o com TF-IDF e prepara√ß√£o dos dados para o modelo.
6.  **Treinamento de Modelos** ‚Äì Aplica√ß√£o de algoritmos de Machine Learning, como Naive Bayes, para classifica√ß√£o.
7.  **An√°lise Textual Explorat√≥ria** ‚Äì Identifica√ß√£o de padr√µes lingu√≠sticos e vocabul√°rio frequente em fake news.

## üìä Fluxo do Pipeline de An√°lise de Fake News


<img width="1920" height="1080" alt="fluxograma" src="https://github.com/user-attachments/assets/6611d4f0-298b-4efc-bca8-a38f65511e47" />

## Desenvolvimento e Implementa√ß√£o

A fase final do projeto concentrou-se na implementa√ß√£o do pipeline de leitura, processamento e classifica√ß√£o usando Python. O c√≥digo foi executado em um **ambiente Databricks**, utilizando a biblioteca `pymongo` para interagir com o MongoDB Atlas.

Abaixo, um resumo das etapas implementadas no script:

#### 1. Conex√£o com o MongoDB Atlas

Primeiro, estabelecemos a conex√£o com o cluster do MongoDB Atlas usando a URI de conex√£o fornecida:

```python
from pymongo import MongoClient

conn_uri = "mongodb+srv://Databricks:1234@pmd2025marcelopirro.nhnozvy.mongodb.net/?retryWrites=true&w=majority"
client = MongoClient(conn_uri)
db = client["Fake_and_Real"]
```

#### 2. Carregamento dos Dados

Os dados, previamente inseridos nas *collections* `Fake` e `Real`, foram carregados em DataFrames do Pandas para facilitar a manipula√ß√£o:

```python
collection_fake = db["Fake"]
fake_data = list(collection_fake.find())
df_fake = pd.DataFrame(fake_data)

collection_real = db["Real"]
real_data = list(collection_real.find())
df_real = pd.DataFrame(real_data)
```

#### 3. Pr√©-processamento e Unifica√ß√£o

Criamos uma coluna `label` para diferenciar as not√≠cias (`0` para falsas, `1` para verdadeiras) e unificamos os dois conjuntos de dados. Em seguida, aplicamos uma fun√ß√£o de limpeza nos textos para remover caracteres especiais, converter para min√∫sculas e retirar *stopwords*:

```python
df_fake["label"] = 0
df_real["label"] = 1
df_total = pd.concat([df_fake, df_real], ignore_index=True)

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    tokens = text.split()
    tokens = [word for word in tokens if word not in stopwords.words('english')]
    return ' '.join(tokens)

df_total["clean_text"] = df_total["text"].apply(preprocess_text)
```

#### 4. Vetoriza√ß√£o e Treinamento do Modelo

Utilizamos a t√©cnica **TF-IDF (Term Frequency-Inverse Document Frequency)** para converter o texto em vetores num√©ricos, limitando o vocabul√°rio √†s 5000 palavras mais relevantes. Por fim, dividimos os dados em conjuntos de treino e teste e treinamos um modelo de classifica√ß√£o **Multinomial Naive Bayes**:

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB

vectorizer = TfidfVectorizer(max_features=5000)
X_vect = vectorizer.fit_transform(df_total["clean_text"])
y = df_total["label"]

X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.2, random_state=42)

model = MultinomialNB()
model.fit(X_train, y_train)
```
## Avalia√ß√£o dos Resultados

O desempenho do modelo foi avaliado com um relat√≥rio de classifica√ß√£o e uma matriz de confus√£o, que nos permitem medir a acur√°cia, precis√£o e outras m√©tricas importantes para validar a efic√°cia da classifica√ß√£o.

O modelo treinado com **Multinomial Naive Bayes** apresentou um excelente desempenho na tarefa de detec√ß√£o autom√°tica de *fake news*. A avalia√ß√£o do modelo no conjunto de teste resultou em uma **acur√°cia de 94%**, com m√©tricas equilibradas para ambas as classes (not√≠cias falsas e verdadeiras).

Abaixo, destacamos os principais resultados obtidos:

- **Precision** de 94% em ambas as classes, indicando uma baixa taxa de falsos positivos.
- **Recall** de 94% para a classe 0 (fake) e 93% para a classe 1 (real), refletindo uma boa capacidade de identifica√ß√£o dos casos reais.
- **F1-score** de 0.94 e 0.93, demonstrando equil√≠brio entre precis√£o e recall.
- **Matriz de confus√£o** evidencia que a grande maioria das previs√µes foram corretas, com poucos erros relativos.

O pipeline, demonstrou ser eficaz ao integrar **MongoDB Atlas**, **Pymongo**, e **Scikit-learn** em um ambiente **Databricks**, viabilizando um fluxo completo de ingest√£o, processamento e classifica√ß√£o de textos jornal√≠sticos em larga escala.

---

#### M√©tricas Principais (Para cada classe):

| **M√©trica**   | **Classe 0 (Fake)** | **Classe 1 (Real)** | **Explica√ß√£o**                                                                 |
|---------------|---------------------|----------------------|----------------------------------------------------------------------------------|
| Precision     | 0.94                | 0.94                 | 94% das previs√µes positivas est√£o corretas (baixa taxa de falsos positivos)      |
| Recall        | 0.94                | 0.93                 | 94% / 93% dos casos reais foram identificados (baixa taxa de falsos negativos)  |
| F1-Score      | 0.94                | 0.93                 | M√©dia harm√¥nica entre Precision e Recall (√≥timo equil√≠brio entre ambos)         |
| Support       | 4733                | 4247                 | N√∫mero de amostras em cada classe no conjunto de teste                          |

#### M√©tricas Globais:

| **M√©trica**     | **Valor** | **Explica√ß√£o**                                                                 |
|-----------------|-----------|----------------------------------------------------------------------------------|
| Accuracy        | 0.94      | 94% de acerto geral (excelente para problemas balanceados)                     |
| Macro Avg       | 0.94      | M√©dia simples das m√©tricas (igual peso para ambas as classes)                  |


A matriz de confus√£o abaixo representa o desempenho do modelo na tarefa de classifica√ß√£o de not√≠cias falsas (Fake) e verdadeiras (Real):

```
[[4467  266]
 [ 285 3962]]
```

|                         | **Previsto: Fake (0)** | **Previsto: Real (1)** |
|-------------------------|------------------------|-------------------------|
| **Verdadeiro: Fake (0)**| 4467 ‚úÖ (Verdadeiro Negativo - TN) | 266 ‚ùå (Falso Positivo - FP) |
| **Verdadeiro: Real (1)**| 285 ‚ùå (Falso Negativo - FN)       | 3962 ‚úÖ (Verdadeiro Positivo - TP) |

---

##### üß† Interpreta√ß√£o:

- **4467** not√≠cias falsas foram corretamente classificadas como falsas (**Verdadeiros Negativos**).
- **3962** not√≠cias verdadeiras foram corretamente classificadas como verdadeiras (**Verdadeiros Positivos**).
- **266** not√≠cias verdadeiras foram incorretamente classificadas como falsas (**Falsos Positivos**).
- **285** not√≠cias falsas foram incorretamente classificadas como verdadeiras (**Falsos Negativos**).

---


## An√°lise Quantitativa
### 1. Palavras Mais Frequentes por Classe
A an√°lise das palavras mais frequentes em not√≠cias falsas e reais revela padr√µes lingu√≠sticos distintos entre os dois grupos. Nas fake news, termos como "hillary", "clinton", "obama", "trump" e "donald" dominam o vocabul√°rio, indicando um forte vi√©s pol√≠tico e a utiliza√ß√£o de figuras polarizadoras para chamar aten√ß√£o. Palavras como "us", "president", "people" e "state" sugerem um foco em temas nacionais e governamentais, frequentemente associados a teorias da conspira√ß√£o ou desinforma√ß√£o estrat√©gica. Al√©m disso, o uso de termos como "would", "even", "like" e "said" aponta para um tom mais hipot√©tico e emocional, caracter√≠stico de manchetes sensacionalistas.

Por outro lado, as not√≠cias reais apresentam um perfil lingu√≠stico mais neutro e factual. Termos como "washington", "united", "states", "government" e "republican" refletem uma abordagem mais institucional e formal, t√≠pica de ve√≠culos jornal√≠sticos tradicionais. Express√µes como "told", "could", "last" e "house" indicam um discurso mais descritivo e menos carregado de emo√ß√£o. Embora "trump" e "president" tamb√©m apare√ßam com frequ√™ncia, seu uso √© menos dominante e mais contextualizado, sugerindo uma cobertura mais equilibrada.

Esses resultados destacam diferen√ßas claras na linguagem utilizada por cada tipo de conte√∫do. Not√≠cias falsas tendem a explorar nomes pr√≥prios e termos emocionalmente carregados para criar narrativas persuasivas, enquanto not√≠cias reais priorizam um vocabul√°rio mais t√©cnico e imparcial. Essa distin√ß√£o pode ser √∫til no desenvolvimento de modelos de detec√ß√£o de fake news, que podem se beneficiar da identifica√ß√£o desses padr√µes lingu√≠sticos.
<img width="1381" height="552" alt="image" src="https://github.com/user-attachments/assets/6fb4deb7-536c-42b8-a818-f4ea10d8ed5d" />

### 2. Nuvem de Palavras (Word Cloud)
As nuvens de palavras geradas para fake news e not√≠cias reais refor√ßam e complementam os padr√µes identificados na an√°lise de frequ√™ncia de termos, oferecendo uma visualiza√ß√£o intuitiva das diferen√ßas lingu√≠sticas entre os dois grupos.

Fake News:
Na nuvem de palavras das fake news, destacam-se visualmente termos como "Trump", "Hillary", "Clinton", "Obama" e "president", confirmando o foco em figuras pol√≠ticas polarizadoras. A presen√ßa marcante desses nomes pr√≥prios, muitas vezes em tamanhos maiores devido √† sua alta frequ√™ncia, sugere que as fake news frequentemente se aproveitam da notoriedade dessas personalidades para atrair aten√ß√£o e engajamento. Al√©m disso, palavras como "people", "us", "state" e "time" aparecem com destaque, indicando uma tend√™ncia a abordar temas de interesse nacional de forma sensacionalista ou manipuladora. A repeti√ß√£o de termos como "would" e "even" refor√ßa o tom hipot√©tico e emocional, caracter√≠stico de manchetes projetadas para provocar rea√ß√µes imediatas.

Not√≠cias Reais:
Em contraste, a nuvem de palavras das not√≠cias reais apresenta um vocabul√°rio mais diversificado e menos centrado em indiv√≠duos espec√≠ficos. Termos como "Washington", "United", "States", "government" e "House" predominam, refletindo uma abordagem mais institucional e factual. A presen√ßa de palavras como "told", "last" e "new" sugere um discurso mais informativo e menos carregado de opini√£o ou emo√ß√£o. Embora "Trump" e "president" ainda apare√ßam, seu tamanho relativo √© menor, indicando uma cobertura mais equilibrada e menos focada em personalidades.
<img width="1185" height="307" alt="image" src="https://github.com/user-attachments/assets/4b4f1904-00c9-443c-9312-19daf86eaa4c" />

### 3. Distribui√ß√£o de Tamanho dos Textos
A an√°lise da distribui√ß√£o do tamanho dos textos mostra que a maioria se concentra entre 0 e 5.000 caracteres, revelando uma predomin√¢ncia de textos relativamente curtos. Observa-se um pico em torno de 2.000 caracteres, principalmente na curva associada ao label 0 (falso), o que sugere que esses textos tendem a ser ligeiramente mais longos. Apesar dessas diferen√ßas sutis, as distribui√ß√µes entre os r√≥tulos s√£o bastante semelhantes, indicando que o tamanho dos textos, isoladamente, pode n√£o ser um fator decisivo para a diferencia√ß√£o entre as classes
<img width="886" height="557" alt="image" src="https://github.com/user-attachments/assets/180d2460-54a0-427c-84c2-d9b5b69f7736" />

### 4. Frequ√™ncia de Bigramas (Pares de Palavras)
A an√°lise de bigramas revela diferen√ßas marcantes na constru√ß√£o lingu√≠stica entre fake news e not√≠cias reais. Nos conte√∫dos falsos, observa-se uma predomin√¢ncia de combina√ß√µes envolvendo figuras pol√≠ticas polarizadoras, como "donald trump", "hillary clinton" e "barack obama", que juntas representam a maioria dos pares mais frequentes. Este padr√£o sugere uma estrat√©gia deliberada de associar a desinforma√ß√£o a personalidades j√° carregadas de significado pol√≠tico, aproveitando-se de vieses cognitivos pr√©-existentes no p√∫blico. Al√©m disso, a presen√ßa de termos institucionais como "white house" e "united states", frequentemente descontextualizados, parece servir para emprestar uma falsa aura de credibilidade ao conte√∫do.

Em contraste, as not√≠cias reais apresentam uma estrutura lingu√≠stica mais diversificada e jornalisticamente convencional. Bigramas como "trump said" e "said statement" seguem o padr√£o profissional de atribui√ß√£o clara de fontes, enquanto combina√ß√µes como "prime minister" e "north korea" demonstram uma cobertura mais ampla de temas internacionais. A presen√ßa consistente de verbos de relato ("said") e a maior variedade tem√°tica indicam uma abordagem mais equilibrada e contextualizada dos fatos. Vale notar que alguns termos como "white house" aparecem em ambos os grupos, por√©m com usos distintos: nas fake news tendem a aparecer isolados, enquanto nas not√≠cias reais est√£o normalmente inseridos em estruturas gramaticais mais completas.

Estes achados t√™m implica√ß√µes pr√°ticas significativas para o combate √† desinforma√ß√£o. Sistemas automatizados de detec√ß√£o de fake news podem se beneficiar ao incorporar a an√°lise de bigramas, priorizando alertas para sequ√™ncias repetitivas de nomes pr√≥prios e a aus√™ncia de estruturas de atribui√ß√£o t√≠picas do jornalismo profissional. Da mesma forma, iniciativas de educa√ß√£o midi√°tica deveriam enfatizar como identificar esses padr√µes lingu√≠sticos distintos, capacitando o p√∫blico a reconhecer as estrat√©gias discursivas t√≠picas da desinforma√ß√£o. Para pesquisas futuras, seria produtivo investigar como esses padr√µes se modificam em contextos espec√≠ficos, como per√≠odos eleitorais ou crises internacionais, e como se relacionam com as din√¢micas de viraliza√ß√£o nas redes sociais.
<img width="1350" height="536" alt="image" src="https://github.com/user-attachments/assets/2b0ec9da-d07b-4081-a148-5def1e163bbe" />

### 5. Frequ√™ncia de Trigramas (Pares de Palavras)
A an√°lise de trigramas (combina√ß√µes de tr√™s palavras) revela padr√µes ainda mais distintos entre fake news e not√≠cias reais do que os observados nos bigramas. Nos conte√∫dos falsos, destacam-se estruturas que combinam termos institucionais com alega√ß√µes n√£o verificadas, como "century wire says" e "video screen capture", que sugerem tentativas de validar informa√ß√µes atrav√©s de supostas evid√™ncias visuais ou fontes obscuras. A presen√ßa marcante de "president barack obama", "president donald trump" e "president united states" em contextos desconexos indica a apropria√ß√£o de cargos e institui√ß√µes para dar apar√™ncia de legitimidade a conte√∫dos enganosos.

Not√≠cias reais, por outro lado, apresentam trigramas que refletem pr√°ticas jornal√≠sticas convencionais, como "white house said" e "reuters president donald", que demonstram preocupa√ß√£o com atribui√ß√£o precisa de declara√ß√µes. A variedade de combina√ß√µes, incluindo "secretary state rex" (referindo-se a Rex Tillerson) e "president vladimir putin", mostra uma cobertura mais ampla e contextualizada de assuntos pol√≠ticos. Curiosamente, enquanto as fake news usam "new york times" de forma isolada, possivelmente para se aproveitar da credibilidade do ve√≠culo, as not√≠cias reais mencionam "new york routers" em contextos espec√≠ficos de infraestrutura.

Estes padr√µes sugerem que:

- Fake news utilizam trigramas para criar falsas associa√ß√µes entre institui√ß√µes, pessoas p√∫blicas e alega√ß√µes n√£o verificadas

- Not√≠cias reais empregam combina√ß√µes de tr√™s palavras principalmente para:

    - Atribuir declara√ß√µes de forma precisa

    - Contextualizar informa√ß√µes dentro de estruturas narrativas mais complexas

    - Abordar uma gama mais diversificada de t√≥picos
<img width="1345" height="671" alt="image" src="https://github.com/user-attachments/assets/01acef1c-ee55-4989-a6c2-bfa105dc8640" />

### 6.An√°lise de Sentimento
O gr√°fico em formato de boxplot mostra a distribui√ß√£o dos escores de sentimento para as classes "Fake" (vermelha) e "Real" (verde), variando de -1.0 (sentimento totalmente negativo) a +1.0 (totalmente positivo). As medianas de ambas as classes est√£o pr√≥ximas de 0.00, sugerindo que os textos, em m√©dia, tendem ao sentimento neutro ‚Äî independentemente do r√≥tulo.

No entanto, h√° varia√ß√µes importantes que merecem aten√ß√£o:

- Classe Fake: Exibe uma leve dispers√£o maior de sentimentos negativos, com alguns outliers indo para extremos negativos. Isso pode indicar que textos falsos tendem a carregar uma carga emocional mais negativa em certos casos.

- Classe Real: Embora tamb√©m centrada em 0, possui uma distribui√ß√£o similar, com outliers nos extremos positivos e negativos. Isso sugere que textos reais tamb√©m apresentam polaridade emocional variada.

Apesar das medianas neutras, o boxplot revela a presen√ßa de outliers que indicam varia√ß√µes relevantes de polaridade entre as classes. Esses desvios podem ser √∫teis na modelagem preditiva, principalmente se combinados com outras vari√°veis lingu√≠sticas ‚Äî como intensidade de polaridade, subjetividade ou presen√ßa de palavras-chave emocionais.
<img width="878" height="551" alt="image" src="https://github.com/user-attachments/assets/ced27d4f-09ee-47e3-a9bf-eeeb54087a29" />

### 7. Correla√ß√£o entre Features
Os dados revelam padr√µes sutis, por√©m consistentes, na estrutura textual entre fake news (label 0) e not√≠cias reais (label 1). Em m√©dia, os textos classificados como fake news apresentam maior extens√£o tanto em caracteres (1740.86 vs 1719.16) quanto em contagem de palavras (230.74 vs 226.66), com diferen√ßas relativas de 1.26% e 1.8%, respectivamente. Esses resultados sugerem que conte√∫dos falsos podem adotar estrat√©gias de redund√¢ncia ou repeti√ß√£o para refor√ßar mensagens, contrariando a percep√ß√£o comum de que seriam invariavelmente mais curtos.

A an√°lise aponta para a relev√¢ncia dessas features em modelos de detec√ß√£o, especialmente quando combinadas com outros padr√µes j√° identificados (como uso de n-gramas e polaridade emocional). Not√≠cias reais, por sua vez, demonstram maior concis√£o, possivelmente refletindo pr√°ticas editoriais mais rigorosas. Como pr√≥ximo passo, sugere-se investigar m√©tricas derivadas (como densidade caracteres/palavra) e a signific√¢ncia estat√≠stica dessas diferen√ßas, al√©m de cruzar esses dados com an√°lises de complexidade lexical e origem dos conte√∫dos.

| Classe      | M√©dia de Caracteres (text_length) | M√©dia de Palavras (word_count) |
|-------------|----------------------------------|-------------------------------|
| Fake News (0) | 1740.86                          | 230.74                        |
| Not√≠cias Reais (1) | 1719.16                          | 226.66                        |


## Conclus√£o:

O modelo errou relativamente pouco em ambos os sentidos:

- Baixo n√∫mero de **falsos positivos** (not√≠cia verdadeira sendo marcada como falsa);
- Baixo n√∫mero de **falsos negativos** (not√≠cia falsa sendo considerada verdadeira).

Esses resultados confirmam que o modelo est√° **bem equilibrado** e apresenta **excelente desempenho**, o que tamb√©m √© refletido nas m√©tricas globais (accuracy, precision, recall, f1-score).

Este trabalho realizou uma an√°lise detalhada de fake news e not√≠cias reais utilizando uma infraestrutura tecnol√≥gica composta por MongoDB Atlas, PyMongo e Databricks. Essa combina√ß√£o mostrou-se extremamente eficiente para todo o fluxo de trabalho, desde o armazenamento dos dados at√© a execu√ß√£o das an√°lises textuais e estat√≠sticas. O MongoDB Atlas foi utilizado como banco de dados principal, armazenando tanto os textos brutos quanto os metadados e resultados das an√°lises processadas. Sua estrutura flex√≠vel de documentos JSON permitiu acomodar facilmente diferentes tipos de dados, desde o conte√∫do textual original at√© as features extra√≠das, como n-gramas e scores de sentimento.

A integra√ß√£o com o PyMongo foi fundamental para conectar o ambiente de an√°lise ao banco de dados. Essa biblioteca Python permitiu opera√ß√µes eficientes de inser√ß√£o, consulta e atualiza√ß√£o dos dados, garantindo que todas as etapas do processamento fossem adequadamente registradas. No Databricks, os notebooks proporcionaram um ambiente colaborativo e organizado para desenvolver as an√°lises, com a vantagem adicional de poder visualizar os resultados diretamente no mesmo ambiente onde o c√≥digo era executado. Essa combina√ß√£o de tecnologias mostrou-se particularmente adequada para projetos de an√°lise textual, oferecendo o equil√≠brio ideal entre flexibilidade e poder de processamento.

Uma das principais vantagens dessa arquitetura foi sua escalabilidade. O MongoDB Atlas garantiu desempenho consistente mesmo com o crescimento do volume de dados, enquanto o Databricks forneceu a capacidade computacional necess√°ria para as an√°lises mais complexas. A natureza schemaless do MongoDB provou-se especialmente √∫til durante o desenvolvimento, permitindo adaptar a estrutura dos dados conforme novas necessidades de an√°lise surgiam, sem exigir mudan√ßas complexas no banco de dados. Essa flexibilidade foi crucial para um projeto de pesquisa que evoluiu iterativamente, com a descoberta de novas features e m√©tricas ao longo do trabalho.

Os aprendizados dessa experi√™ncia destacam o potencial dessa stack tecnol√≥gica para projetos de processamento de linguagem natural. A aus√™ncia de PySpark n√£o se mostrou uma limita√ß√£o, demonstrando que solu√ß√µes baseadas em Python puro podem ser perfeitamente adequadas para muitos cen√°rios de an√°lise textual. Para trabalhos futuros, recomenda-se explorar ainda mais as capacidades do MongoDB Atlas, como a implementa√ß√£o de √≠ndices de texto completo para consultas mais sofisticadas, e a automa√ß√£o de pipelines para atualiza√ß√£o cont√≠nua das an√°lises. Esta abordagem mostrou-se robusta o suficiente para servir como base para pesquisas mais avan√ßadas na √°rea de detec√ß√£o de desinforma√ß√£o.

Os resultados sugerem que a combina√ß√£o dessas caracter√≠sticas pode servir como base eficaz para sistemas de classifica√ß√£o autom√°tica, destacando-se especialmente o potencial da an√°lise de trigramas e padr√µes de sentimento como features discriminativas. Para o p√∫blico geral, estes achados oferecem indicadores pr√°ticos para identifica√ß√£o de conte√∫do suspeito, como excesso de nomes de figuras p√∫blicas, tom emocional extremo e falta de fontes claramente atribu√≠das. Apesar das limita√ß√µes inerentes ao escopo do estudo - como a necessidade de valida√ß√£o em diferentes contextos culturais e temporais - esta pesquisa fornece evid√™ncias robustas sobre as assinaturas lingu√≠sticas da desinforma√ß√£o, abrindo caminho tanto para o aprimoramento de ferramentas tecnol√≥gicas quanto para estrat√©gias mais efetivas de alfabetiza√ß√£o midi√°tica. Como pr√≥ximos passos, podemos ter a integra√ß√£o dessas descobertas em modelos preditivos e a cria√ß√£o de materiais educativos que traduzam esses padr√µes em orienta√ß√µes acess√≠veis para o p√∫blico geral.

# üìö Refer√™ncias Bibliogr√°ficas Sugeridas

1. **MongoDB Atlas e Integra√ß√£o com Python (PyMongo)**  
   MongoDB, Inc. (2024). *A Guide to Connect Databricks and MongoDB Atlas using Python API*. CloudThat.  
   Dispon√≠vel em: [https://www.cloudthat.com/resources/blog/a-guide-to-connect-databricks-and-mongodb-atlas-using-python-api](https://www.cloudthat.com/resources/blog/a-guide-to-connect-databricks-and-mongodb-atlas-using-python-api)  

2. **Databricks e Processamento de Dados com MongoDB Atlas**  
   Raisinghani, A. (2024). *Utilizing PySpark to Connect MongoDB Atlas with Azure Databricks*. MongoDB Developer Center.  
   Dispon√≠vel em: [https://www.mongodb.com/developer/languages/python/atlas-databricks-pyspark-demo](https://www.mongodb.com/developer/languages/python/atlas-databricks-pyspark-demo)  

3. **Documenta√ß√£o Oficial do PyMongo**  
   MongoDB, Inc. (2025). *PyMongo Documentation*.  
   Dispon√≠vel em: [https://pymongo.readthedocs.io](https://pymongo.readthedocs.io)  

4. **Documenta√ß√£o Oficial do Databricks**  
   Databricks, Inc. (2025). *Databricks Documentation*.  
   Dispon√≠vel em: [https://docs.databricks.com](https://docs.databricks.com)  

